{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20064a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbe7b3c7",
   "metadata": {},
   "source": [
    "Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db043861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "\n",
    "embed_size = 384\n",
    "num_heads = 6\n",
    "num_blocks = 6\n",
    "\n",
    "dropout = 0.2\n",
    "# Optimal lr is found by find_lr() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdc7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 54, 56,  ..., 52, 53, 52],\n",
      "        [58,  1, 53,  ..., 42, 53, 57],\n",
      "        [58, 46, 43,  ..., 42, 47, 43],\n",
      "        ...,\n",
      "        [43, 43, 58,  ..., 43,  1, 40],\n",
      "        [58,  1, 42,  ..., 50,  1, 47],\n",
      "        [26, 53, 56,  ..., 31, 32, 17]])\n",
      "tensor([[54, 56, 47,  ..., 53, 52, 43],\n",
      "        [ 1, 53, 44,  ..., 53, 57, 58],\n",
      "        [46, 43,  1,  ..., 47, 43,  1],\n",
      "        ...,\n",
      "        [43, 58,  1,  ...,  1, 40, 56],\n",
      "        [ 1, 42, 47,  ...,  1, 47, 52],\n",
      "        [53, 56,  1,  ..., 32, 17, 30]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elumixor/projects/nano-gpt/data/load_data.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(vocab.encode(text), dtype=torch.long, device=device)\n"
     ]
    }
   ],
   "source": [
    "from data import load_data, DataLoader\n",
    "\n",
    "trn, val, vocab = load_data()\n",
    "\n",
    "Loader = lambda ds: DataLoader(ds, block_size=block_size, batch_size=batch_size)\n",
    "\n",
    "trn_loader = Loader(trn)\n",
    "val_loader = Loader(val)\n",
    "\n",
    "x, y = next(iter(trn_loader))\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24797ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_loss=2.45733\n",
      "optimal_lr=0.15495\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGeCAYAAADITEj7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFW0lEQVR4nO3dd5hU5cH+8e+ZsrO9wjZY2BWlgyAgghXF3pNoNMZgS2LJa0uMNWo0BE3yRqJJbK8/NDHWWGPDEuyiIEWadNilbWHLbJ12nt8fg6soKLs7u2dmuT/Xda6LHabcZxc4N895znMsY4xBREREJAZcTgcQERGR3kPFQkRERGJGxUJERERiRsVCREREYkbFQkRERGJGxUJERERiRsVCREREYkbFQkRERGJGxUJERERixtPTH2jbNlu2bCEjIwPLsnr640VERKQTjDE0NjZSXFyMy/Ut4xKmg/x+v7niiivMgAEDTHJyspk0aZL55JNP9vj1FRUVBtCmTZs2bdq0JeBWUVHxrcf5Do9YXHTRRSxdupR//vOfFBcX8+ijjzJ16lSWL19Ov379vvP1GRkZAFRUVJCZmdnRjxcREREH+P1+SkpK2o/ju2N15CZkra2tZGRk8MILL3DiiSe2Pz5mzBhOOukkfve73+1RsKysLBoaGlQsREREEsSeHr87NGIRDoeJRCIkJyfv9HhKSgrvv//+Ll8TCAQIBAI7BRMREZHeqUNXhWRkZDBp0iRuv/12tmzZQiQS4dFHH+Xjjz9m69atu3zNjBkzyMrKat9KSkpiElxERETiT4dOhQCsXbuWCy64gHfffRe3280BBxzA4MGDWbBgAcuXL//G83c1YlFSUqJTISIiIgmkW06FAAwaNIh33nmH5uZm/H4/RUVF/PCHP6SsrGyXz/f5fPh8vo5+jIiIiCSgTi+QlZaWRlFREXV1dcyePZtTTz01lrlEREQkAXV4xGL27NkYYxgyZAhr1qzhmmuuYciQIZx//vndkU9EREQSSIdHLBoaGrjssssYOnQoP/nJTzjkkEN4/fXX8Xq93ZFPREREEkiHJ292ldaxEBERSTx7evzWTchEREQkZlQsREREJGZULERERCRmVCxEREQkZjp8uamIiIjEp1tfXIbLsrjy6P3ITHbmak2NWIiIiPQCxhge/nAD/++D9QRCtmM5VCxERER6geZgpP3XXrflWA4VCxERkQT3+TY/I2+Z3f61x+3c4V3FQkREJMHNfGP1Tl9rxEJEREQ6Ldm78+Hc69KIhYiIiHRSstfd/muXBS6XRixERESkk75aLLwOzq8AFQsREZGE5/N8eTjv0TuL7oKKhYiISIJL+kqxCIadW8MCVCxEREQSXiji9DjFl1QsREREEpzToxRfpWIhIiKS4IKRyHc/qYeoWIiIiCQ4jViIiIhIzMRTsdBt00VERBJcMBItFtd5HiOIB1omQWquI1lULERERBJcMGxjYfMz98u4LAOROx3LolMhIiIiCS4QtsmgNVoqAJKzHcuiYiEiIpLggmGbTKsZgDbjBW+yY1lULERERBJcMGKTRbRY1JPuaBYVCxERkQQXDNtk7RixaDBpjmZRsRAREUlw4YhpH7FoQMVCREREuiAU0YiFiIiIxEjItpng+hyA4gH7OppFxUJERCTBRcIRjnF9CsCI437qaBYVCxERkQRXENlKhtWK7fZB8QGOZlGxEBERSXD7RdYCEOwzHNzOLqqtYiEiIpLghpposQjlj3Y4iYqFiIhIwhtiNgAQLlCxEBERkS7qS230F9kDnA2CioWIiEhCm7ehlnSrFQB3SrazYVCxEBERSVgbapo5476PSKcNAFeys/cJARULERGRhLV0SwNgSCM6YuFJyXI2ECoWIiIiCSsQskkhgNsyAHhTMx1OpGIhIiKSsIIRm/QdoxW2sXD7dCpEREREOikQipBuRedXNJMMluVwIhULERGRhPXVEYsmUh1OE6ViISIikqACIZvMHbdLb7ZSHE4T1aFiEQ6HuemmmygrKyMlJYV99tmH2267Ddu2uyufiIiI7EYgbFNIHQBV5DqcJqpDdyq58847ue+++3jkkUcYMWIE8+fP5/zzzycrK4srrriiuzKKiIjILgQjNoVWdNXNKvIcThPVoWLx0Ucfceqpp3LiiScCUFpayuOPP878+fO7JZyIiIjsXiAUYYC1HYAqKz6KRYdOhRxyyCG89dZbrFq1CoDFixfz/vvvc8IJJ+z2NYFAAL/fv9MmIiIiXReM2BRY0VMh1Yl4KuTaa6+loaGBoUOH4na7iUQiTJ8+nbPPPnu3r5kxYwa//e1vuxxUREREdhYI2WRbTQA0WM4vjgUdHLF48sknefTRR3nsscdYsGABjzzyCH/605945JFHdvua66+/noaGhvatoqKiy6FFREQEWkMRsoleFdJkOb84FnRwxOKaa67huuuu46yzzgJg1KhRbNy4kRkzZjBt2rRdvsbn8+Hz+bqeVERERHbSEoyQteNyU3+cFIsOjVi0tLTgcu38ErfbrctNRUREHNASCJG1Y8Si2RUfxaJDIxYnn3wy06dPZ8CAAYwYMYKFCxfy5z//mQsuuKC78omIiMhuRIIt+KwQAE1WhsNpojpULO655x5+85vfcOmll1JVVUVxcTE///nPufnmm7srn4iIiOyGJxC90jJsXLTGycqbHSoWGRkZzJw5k5kzZ3ZTHBEREdlT7mC0WDSSiuVy/gZkoHuFiIiIJCx3OHqpaaNJwRUHdzYFFQsREZGE5d1RLJpIVbEQERGRzgtFbJLt6C3TG0khPmqFioWIiEhCag1FSLeixaLZJBMnAxYqFiIiIokoEjFkEC0WTWiOhYiIiHRBxBjSvygWJkUjFiIiItJ5tm3aT4U0asRCREREuiJsf33EQsVCREREOinylRGLZlKIk/WxVCxEREQSkf2VORaNaI6FiIiIdEH4KyMWTVp5U0RERLrCtne+3FRzLERERKTTwrYh7auTNx3O8wUVCxERkQQU+cblpg4H2kHFQkREJAH94l+ftk/ebDYppPk8DieKUrEQERFJQFtrG0iyIgD07ZPH7aeOdDhRVHzUGxEREdljEduQSyMAIePmxauPB1d8jBXERwoRERHZY8GwTZG1HYBKcuKmVICKhYiISMIJhCMUWbUAbDF5DqfZmYqFiIhIggmEbQp3jFhsM7kOp9mZioWIiEiCCYRsijViISIiIrEQCEc0YiEiIiKxEQh/OWKxVcVCREREuiI6YvFFsdCpEBEREemCQDBCHxoAqDbZzob5GhULERGRBBMKtODdseqmn1SH0+xMxUJERCTBRNqioxW2sWjB53CanalYiIiIJBjT6gegiRRMnB3K4yuNiIiIfCfTFi0W8XYaBFQsREREEk6kNXoqpMmkOJzkm1QsREREEkxLYx0AjahYiIiISBe1NtYDGrEQERGRLvK3hdiwZSsAjZpjISIiIl1x4t3vkRxpAaDRqFiIiIhIF1TUtpJh7SgWmmMhIiIiXZVOK6ARCxEREYmBL0YsmjRiISIiIl2VyRdzLOKvWHicDiAiIiIdk25FT4W0ulL5x3kHOpxmZyoWIiIiCSZjxxyL2344mb6D+zqcZmc6FSIiIpJgsqxmAFwp2c4G2QUVCxERkYRiyKERACutj8NZvqlDxaK0tBTLsr6xXXbZZd2VT0RERL4ig1a8VgQAd2qew2m+qUNzLObNm0ckEmn/eunSpRx99NGcccYZMQ8mIiIiO7NtQ44VHa1oNj7cyfG3jkWHikXfvjtPELnjjjsYNGgQhx9+eExDiYiIyDeFbJvcHadB6sigj8tyONE3dfqqkGAwyKOPPsrVV1+NZe1+xwKBAIFAoP1rv9/f2Y8UERHZqwXDNrlW9DhaazIojMNi0enJm88//zz19fWcd9553/q8GTNmkJWV1b6VlJR09iNFRET2aqGIodjaDkClycXdm4rFQw89xPHHH09xcfG3Pu/666+noaGhfauoqOjsR4qIiOzVQhGbEqsKgHKT/61nDJzSqVMhGzdu5M033+TZZ5/9zuf6fD58Pl9nPkZERES+Ihi2KbGqAagw8bUw1hc6NWIxa9Ys8vPzOfHEE2OdR0RERHYjFLEpsmoB2GLi71JT6ESxsG2bWbNmMW3aNDwerQguIiLSU0IRQybRVTfrTbrDaXatw8XizTffpLy8nAsuuKA78oiIiMhuBMN2+3LeDaQ5nGbXOjzkcMwxx2CM6Y4sIiIi8i0CoTBZO0YsGkx8FgvdK0RERCRBNPob2pfz9sfpiIWKhYiISIJo8kfXsAgZNy3E5xWXKhYiIiIJom1HsYjOr4i/NSxAxUJERCRhBJvqgPidXwEqFiIiIgkj3Bxdw6KR+Lur6RdULERERBKEaW0ANGIhIiIiMeALR+9sGq9rWICKhYiISEKYu247VdWVAPhNKn0zdFWIiIiIdNJZD8xtX857YL9+vHHVYQ4n2jUVCxERkQSRuWM574KCQrJTkxxOs2sqFiIiIgkij0YA7ORsZ4N8CxULERGRBNHXqgfATst3Nsi3ULEQERFJEPk7ioVJL3Q2yLdQsRAREUkAbiLkEb3clPQCZ8N8CxULERGRBJCHH5dliBgLV3pfp+PsloqFiIhIAhhgRdew2EoeXq/X4TS7p2IhIiKSAMpc2wBYbxeS5I7fw3f8JhMREZF2pVa0WGwwhSR54vfwHb/JREREBADbNuRTD8BWk4fXbTkb6FuoWIiIiMS5tnCE7B2rbtaRrhELERER6byWYIRsK7rqZr1Jx6s5FiIiItJZrcEI2TtuQFZPuiZvioiISOe1hiJkW01AdMTC5dIcCxEREemk1kCYbL4sFvFMxUJERCTOtbX48VoRAJ6+6gSH03w7FQsREZE4F2muBSCIl/75eQ6n+XYqFiIiInFse1OAO579EIAmVyZY8Tu/AlQsRERE4tptLy0nw0QvNW12Zzic5rupWIiIiMSxDTXN5OyYuNnqznI4zXdTsRAREYljYdu0X2ra5s10OM13U7EQERGJY+GIIYfoqZA2b7azYfaAioWIiEgcC9k2hVYdAC1JfR1O891ULEREROJYxDYUWtHLTZuTCxxO891ULEREROJYOGIotrYD0Jpc6HCa76ZiISIiEsfCtt0+YtGWqhELERER6QJPpI2cHVeFBFOLHE7z3VQsRERE4lieHT0N0mx84NPlpiIiItIFfewaALaaPJK8bofTfDcVCxERkTiWt6NYbDM5JHni/7Ad/wlFRET2Yll2AwDVZONTsRAREZHOagmGybP8ANSZDDyu+D9sx39CERGRvVSVP0DujuW8t5tMXPF9x3SgE8Vi8+bN/PjHPyYvL4/U1FTGjBnDp59+2h3ZRERE9mqV/jZyrWixqCMDKwGKhacjT66rq+Pggw9mypQpvPrqq+Tn57N27Vqys7O7KZ6IiMjeq7EtTO6OUyHbTQYQ/82iQ8XizjvvpKSkhFmzZrU/VlpaGutMIiIiAoQidvudTWtNZkKMWHToVMiLL77I+PHjOeOMM8jPz2fs2LE8+OCD3/qaQCCA3+/faRMREZHvFozY7ZM3a8lIgPGKDhaLdevWce+997Lffvsxe/ZsLr74Yi6//HL+8Y9/7PY1M2bMICsrq30rKSnpcmgREZG9QSQUJMtqAaDWZJCSFP8LZFnGGLOnT05KSmL8+PF8+OGH7Y9dfvnlzJs3j48++miXrwkEAgQCgfav/X4/JSUlNDQ0kJkZ/0uTioiIOOX59xZw2ltTsI3FL/Z9nb+eMwGXQ5eG+P1+srKyvvP43aERi6KiIoYPH77TY8OGDaO8vHy3r/H5fGRmZu60iYiIyHdzt+64T4g7k7+fe6BjpaIjOlQsDj74YFauXLnTY6tWrWLgwIExDSUiIiKwecsmAJo92c4G6YAOFYurrrqKuXPn8vvf/541a9bw2GOP8cADD3DZZZd1Vz4REZG90trqJlasWgVAkyfX4TR7rkPFYsKECTz33HM8/vjjjBw5kttvv52ZM2dyzjnndFc+ERGRvdK89bUUWbUA+JPyHU6z5zq0jgXASSedxEknndQdWURERGQH20DhjmLR5EucYqF7hYiIiMQh25j2EYvGBBqxULEQERGJQ8YYSq1tANQlFTucZs+pWIiIiMQhEw6yj7UVgK2+UmfDdICKhYiISBzyNW7Ea0VoNCnUunUqRERERLrA1VwJwFaTS2TPF8l2nIqFiIhIHHK1Ridu1pFB2FaxEBERkS5wtdUBUGcyiKhYiIiISGcZY6iriV4RUmvSNWIhIiIinVfVGMBqid6ArI4MbBULERER6axg2CbHagSg1mRQkJnscKI91+ElvUVERKR7BcI2uUSLxcCSEk6dOtjhRHtOxUJERCTOBMM22VYTAD85chykeh1OtOd0KkRERCTOhCI2uTtOhZCaOLdMBxULERGRuBOM2OSgYiEiIiIxEA60kmYFol+k5jkbpoNULEREROJNU3Q57xAe8GU6HKZjVCxERETijMdfDkCVuwAsy+E0HaNiISIiEmdef38uAJWeYoeTdJyKhYiISBypbgyQHdgMQLnd1+E0HadiISIiEkcWVdQzwKoCYBP5DqfpOBULERGROLKuuomSHcVig61iISIiIl3QHIy0j1isj+hUiIiIiHTS9qYAH6/aRO6O5bw3hnMcTtRxuleIiIhInDj0D3PIDlZCMgSNm5pwitOROkwjFiIiInGiJRhpv116HRlAYq1hASoWIiIicSXP8gNQazIpykp2OE3HqViIiIjEkdwdNx/bbjJ4+PwDHU7TcZpjISIiEkf6WA0ADCotpagww+E0HacRCxERkTgy0NpxA7LMAQ4n6RwVCxERkTiyj7UVgEjOIIeTdI6KhYiISBwpdW0DwOTu43CSzlGxEBERiRNuIhRSC4Art9TZMJ2kYiEiIhIHbNtQQB1uyxA0btwZBU5H6hQVCxERkTgQsm2KrO0AVJpcfEmJeeGmioWIiEgcCEUMxTuKxRby8LndDifqHBULERGROBCOfDlisdXk4vMm5iE6MVOLiIj0Mi8v2UqRFZ24udXkkeROzEN0YqYWERHpRVZs9XPjc0vbT4VsNn1wuRLvBmSgYiEiIuK4VZXR+4MUWzVA9FRIolKxEBERcVgwbAN8OXnT9HEyTpeoWIiIiDgsGLFJoY08KzpysVnFQkRERDorGLbbRyv8JgU/aQ4n6jwVCxEREYcFwzb9d8yvSOTRCuhgsbj11luxLGunrbCwsLuyiYiI7BVaQxH69ZJi0eH1QkeMGMGbb77Z/rU7QVcGExERiRfNgTD9rGogsSduQieKhcfj6dAoRSAQIBAItH/t9/s7+pEiIiK9WlMgzIheMmLR4TkWq1evpri4mLKyMs466yzWrVv3rc+fMWMGWVlZ7VtJSUmnw4qIiPRGgbC906mQP/5gtMOJOq9DxWLixIn84x//YPbs2Tz44INs27aNyZMns3379t2+5vrrr6ehoaF9q6io6HJoERGR3iQUMe3FIpzRnzPGJ+5/wjt0KuT4449v//WoUaOYNGkSgwYN4pFHHuHqq6/e5Wt8Ph8+n69rKUVERHoxOxykgDoAtnvyHU7TNV263DQtLY1Ro0axevXqWOURERHZ62QEKnFbhoDx0ORJ3OW8oYvFIhAIsGLFCoqKimKVR0REZK8SithEyucCsNKU4PYk9tWWHSoWv/rVr3jnnXdYv349H3/8MT/4wQ/w+/1Mmzatu/KJiIj0ar9/ZQX7258DMNcejseV2GtXdmiOxaZNmzj77LOpqamhb9++HHTQQcydO5eBAwd2Vz4REZFebdYHG5jljU7cXGuKSfMl9ohFh4rFE0880V05RERE9loFVj0AlSaH354y0tkwXZTY4y0iIiK9QIFVC8AlpxzCvvnpDqfpGhULERERByURar9dup2e+BdDqFiIiIg4KH/HaZCA8UJyYl9qCioWIiIijiogehqk0mTj9ST+YTnx90BERCSBFVjRFTe3kYvHnfiH5cTfAxERkQRWuKNYVJkcvG7L4TRdp2IhIiLioJGu9QBUmL54NWIhIiIinWYMR7kWAPBWZCwel0YsREREpJMWry0ny2oBYJkp1YiFiIiIdN7VD80GwG9SaSVZxUJEREQ6xxjz5RUhJgcAjyZvioiISEcZY3jg3XUUEC0WlTuKhTfB72wKKhYiIiI97u1V1cx49fP2EYsqNGIhIiIinbRiqx/4cnGsL0Ys3L3gqpAO3TZdREREus62DQD5O4pFWdkgLi4eRLLX7WSsmOg1IxbbmwK8/NnW9q9XbmvkhUWbaQtFqGsOYoyhsS0EQFsowlPzKvjFYwtYX9MMwJqqJipqo5f8fLK+lifnldMWigBQ2xzk6fkV3PPWakIRG4Bg2OZfH29kS30r/rYQgXCExrYQxhjCEZuN25u57LEFPP5JObZtaAmG+XjddowxNLSEePDddWzc3tyeZ+nmBm59cRmrKxvb9+Gjtdv5YE0NLcEw/rYQwbBNWyiCMYamQJi//nc11z+7hIbW6H59tqmeuuYgAK8s2cpbKyoJ78hb1djG3+as4dkFm9rfv7oxwJPzymkKRN8/YhuaA2EAIrZh/oZaLvvXAuau297+Hiu3RfNtqGnmnx9twL/je9oSDPPhmhrufO1z6luC7Z/x2tJtrKlqpC0UIRCObrZtMCb6WTNeWcH/vbeOUMTGGMPiinpCERvbNjw1v6L952OMYXtTgLvfWs3C8rr29y/f3sJ7q6sxJvqe8OVfWGMM8zbUMuOVFbQEw+1/Tr74fq2tbmL+htqd/hx9urGW15Zua3+vr2baFWMMLyzaTPn2ll3+XnVj4BuPVdS2tL+/iOyddvwzRcGOG5AdP2ks1x0/1LlAMWSZHv4Xzu/3k5WVRUNDA5mZmTF5zyp/G+//+UcQCWCn9mFwno9F5bV4CWOwSLXaaDYptODDQ4RUAriw8VgRWkwybiI0k0K1yaK/p540uxELQw5NpFutJBHCg00EF40mlZQ+JZQ3e2hsacPCxoON27JpMOmAIYkQXiIkWSGCxouNRQQXW00eSVaIUquSoPGQYbWSZzXgwpBKgAiu6CelF+LKKGDp5gY8RNr3oc5kEMGFG5tUArgtGwubVuPDhaGedBpMGgOtbfisMF7C5NBIihUkmejBPoKLJlcGmfkDWbA1gNtED7g+QoTw0EgKbmySCeLGJskK02qScGFoI4mtJpdsq4lCq5aIcZNptZBjNeLCxkcIGxctxocvr4RGVxbrqxpwY2OAZELUWxlEjIWbCCkE8RDGxkWAJACqTRYhPJRa27CxSCVArtWIhwgpVgCDRci4MemF5BYN5K1VtXiJEMFFKgEaSaHV+HBjk2IFcGFwYdNskkn2QG3YR5XJYXJBiJrqSgyQRTP9UsK0tLVhYQjjxviyGLTfUDa1+vhgdRUAFobCTB9+VxatIZv6plbcRPBg00YSw/vnUd0G71encOKIfDLatjBnXSNptPH94ek0BW3mr91G0HgpK87npMMmUFI2jEue+pzPq9oY3i+H0QOyGVaYSX1rkNH9s3l9WSV/nP05toF/XTSRSfvk8Z/PtjC6fzZlfdJ45tNNpPk8HD28ALfLwhjDnJVVFGQmM6I4q/3viDEGy0r8IVaR3uKuN1Zxz1sr+cR3KX0sP1z4JpRMcDrWt9rT43evKBYAjbcPICPSELP3E3FCyLgJ4aENLxFcJBEmhIcQHupNGiE8VJocKk0O+VY9BoswLnyEsIgWxxZ8NJpU8voNYsKEybxf7ePv721iYEEuOZkZnH34KDY2RJgyJJ+mQJj5G+p46bMtXH7Ufozun+30t0Bkr/C/r69k7pyXeNp3G82uDNJuWAeeJKdjfas9PX73mjkW7uNn8PZny2ms2UJLxEXQuEjyeNjcEKQNL309LaRH/ITwUGOyiOCK/i/bCtFqfBRYdWRYLVSbbOpNOsNK+lJvUlnTYNFqPEwdWUKqB1asL8fbtAVvuIVQxCZkealrjf6vNdfyk0yQOjJoMikYIM1qo9X4SLaCDLCqaDIpbDZ9sHExvKw/n9V5AIvk9CyOG5HPonVbaa7ZRFqolkgkQpLPx9b6NgJ4KfI24Qs30UYS200mBguvFcGFTdB4GGBV4bIM20wOLSaZkaWFbGz1UdXqoj7k5dzJZVTWN7KxvJyUtkrckQAGqGm1CZgkUq028mjAAraTSdB4AUi1ArSaJLKsZgqsWupMBpUmhz5ZqaRl5PJZrQvbcrNvv3xGFqaxZN1mjH8TqWE/gVAYtzeZ2tYQBhe5+Em3WmkyKdSRDkRHMmxcgKHM2kYAL1tNLiE89C/MZ21jEkFjURdO4kcTSli9tZaGqgoyQtVYdnTEozVkEyCJbBrJsxoJ4Wa7ycTGio7AWCHajJcCq45Mq4Uak0mDScPlSSLoyWBrq4cgbkb2zyXFbaip3kpmYBtppgUXNmE82FgkEaKv1UAKARpIo9X4sDBkWC2E8JBKgDJrG834qDQ5WEArvuhnEc2Y4o6QbLfQ36puv/nQF7xWBO+OUbWvK7K+OG2zfs/+UlS+CS/dz+nA6UlAXXQLPuKmr8llC6m0kkS2SeU0kvlodR8+SMllVVs2C8OlXH/KOJqam7njoxZ+cdRgpk0uJRi2Ka9tYcnmek4eXdwr7sQo4oSIbRju2gjAmtT92T/OS0VH9JpikTr+HI4Yv+vfq/S3kexxU9nYxoaaZg7JT8eyLMr6pAGwub6VYNimJCeF/3t/PUeV5jJuYM4u3+uQXTzWFoqwraGNouxknl+4mVP360t5bQsTy3KxLItg2GZRRT3jB+bw4drtBKoaOW9yKZZlcfLX3mvEYbveh3XVTfTLSeHTjXUkuV143S6KspPJz0gG4PNtfnLTkkhyu3jwvXWcfeAA+uek7sF3Lqq+JUhLMILHZfH2ympO368P1Y0B9u+fhWVZ1DYH2VTXwuj+2Tw5r5zBSR5O3r8YgB987b129WMIR2xWVjYytDCTFxZt5sDiLLY0tDKmfzY5aUkYY/hgzXbGDMhm4/Zmli3awv8ctR/pvm/+ER2zi/cPhCOsqWoiJzWJLfWtrKpsYnhhBm2hCOMG5pDsdfPZpuhciWFFmUx/eQVHDMnn6OEFu/2eGGMI218O6L2/uoaG1hD7DszhrjdXMahvOtWNAY4eXsCwslzeXFHFgvI6ThxVxOOflLOgvI77zx3PvjkpuCyLdTXNDMhNJcnjwhjD8q1+FtfUE2xr47D9cnlwzkqe+mQD1xxRzJwFy9jWGKaJFLyEGZvvxhVpY1NtE4OtTSRbQepNOgaLiWV5rK0P09gSoCkQ5uh902msr8HUrmc/azN9rAaSCOHbsSVZEUqs6l3vdAhw79iiCwLyfaBlto+62V62mjxqTCZNpoDH3hnMUcedTuF+47j/vfWMKclm8qA+u/1+isiXIrahzIrOC6xOKnE4TWz1mlMhIr1JMBydLJrk2XlEoCUYxuNyEbZtnvikgtPG9iM3bdf/04nYhi31rdS1BOmT7qOitoXzZn3CaaUhSs1mlq2rIIybdKuVPBrpZ1WTYgUYalUwxKrAhcEAbuvb/4loMKmsN0VUmL6Um3zs7H3IHX00ffvty9RhBVgWLN3sJ9XnZlDf9Jh8f0QS3fSXl3Po3J9xmHsJjxf+mrMvvtHpSN9przsVItKbfL1QfCE1KfpXNgkXFxxS9q3v4XZZlOSmUpIbHbkqzk5hxe3HA9HisqW+lb4ZPpqDYfIzkjHG8OnGOhZs9dNUkMGvnl7EtromXrhwJBu2VLJ60zY2bljHmJw28kNbSK5ZygTX52RZLYyx1jKGtdEPbgI+nEmdSecTU8IGu4ClpozF9iAu//EZHD2ikLZQpFdcVifSWREb9nFFRyyqkvo7nCa2VCxE9kJJHhelO04Fpu043WRZFuNLcxlfmgvAu78+EmPA5bIYvt+gb7xHxDa8uXQTVesWE6xeh6ldj7exgv1d6xhprSfHauIgawUHuVYAbwPQ8NTvedvejzftA2gZeCS3nXssLy2pZNKgPAbmpfXIvovEAyvcSjHRS/lrfAMcThNbKhYiskuWZfFtV6i6XRbHji6B0V+eH/5sUz1zPq+moa/hgSefpZ9Vwz7WNkZZ6xjnWkWW1cIR7sUc4V4MW2YRvMNNf3soT9ojOeDgYzj4sGNISc8kHLFxuyxdIiu9VnpLBS7L0GBSaXJnOx0nplQsRCRmRvfPbr9kdUjplWQke3h3VTWNFizyRrj9kRc41PqM77nfo9TaRpIV4RD3Mg5xL4NPnqTp42Tesofxmj2BnHHf54bvHeTsDol0k+yW6BUh601RryvQKhYi0i0Ks6JXLB0/qqj9sZemX8qiinqyslP4xXOLWfv5Yo5wLeYA1yrGutZQbNVylHshR7kX0rr4YeZWHMvIM27EVzCEQNje5VVCIokos3kDAOtMEfSuXqFiISI9x7Isxg6IXsp994/Gs7l+BIP6/oy2UIR1VY387YX/kLP5HU5xf8hg12YOqvsP9gMv8UZkHM8ylQvPu4gJ+/Tpdf/Dk73Lk/PKcdWsAQ+stwudjhNzKhYi4ohk75eXnyZ73Qzvl830S88FzqWpLcRjL/6bgqUPcJRrAce653Ms89n8jwf5S+RwTjn/evYZNNjZHRDppGufWcK/k7YB0VMhvl42ZKFl80Qk7qQne/nRmWcz9OpXeGDU4zwUPp46k04/aztXep6l7z8O46HbLmTBirVORxXplH2sLcCOUyG9jEYsRCRu9ctO4WffPwG+fwINjY1cPuMOLvC8whjXOi60/03zE/9hVuQIVg86j7JBQzn/4FItMy5xL5tGcq0mADaYQob3rgELjViISGLIysjgf2+/nWfGPszjJbewzi4kzQpwvmc2N2/4CZ7Xr+Ocv7ykW9JLXAtHbMqs6GmQrSaXFpJ72YkQjViISALxul3cfvr+wP787OGDiayazU89r3CQawXne2ZzUsNcnv9/SznmR1eTlpLsdFyRb2gORNrvEdIbJ26CRixEJEHdP+1A7r/9Jt6c8BDTgteyxi6mr9XA6RV3smLGocx4/A2nI4p8Q3MwzCDXzvMrThjdu+ZZqFiISEKyLAuP28VNJ4/gkd/fQMv5c7gtdC5+k8p41you+Xwaj/7tVkw46HRUkXYbt7dwlGshAEvMPtxz9liOGNzX4VSxpWIhIr3C6LJCrvzNXZzJnSyy9yHbaubH1Xex6bbhXPr7v9LQEnI6ogiXPvg6Q10VALwamcCE0txety6LioWI9BqZyV7+c/OPSb/kLX4bOpcqk02Jq5q7A7/hibuuJBKJOB1R9mLGGAZaVUB04qafdHy7uZNxIut9eyQiezWv28W+Rbmc9T8zOCLwZ56LHIzHsvl56FEWzTgKf/UWpyPKXioQthlgVQJQbvKB6OJwvY2KhYj0SkMKM1hw+2mceutLvFx2A60miXHhhbT9dRKfvv0CDa06NSI9q7EtzMAdxWKjXQCgEQsRkUSS7HXjcrs45sfX8N9Dn2CV3Y98q56xc6Yx6w9XUd0YcDqi7EWaAmFKXTuKhYkWC5erd82vABULEdkLeN0uTpx6FOtO+w9PhQ/HZRmuNP9k/WNXgRbUkh7S1BZuPxWy0RRw8v7FDifqHioWIrLXOO6AQRx7wzP8t+QXABy49V+sevA8sG1ng8leobEt0L7qZiR7IPecPdbhRN1DxUJE9ipZqV6OOP93/CP/GsLGxeAtz1P9+M9VLqTbeTfNpY/lx29SuPH87zkdp9t0qVjMmDEDy7K48sorYxRHRKT7uVwW515yIw8V3EDEWPRd/RTP/e5MFpXXOh1NerHkygUALEubSP++eQ6n6T6dLhbz5s3jgQceYPTo0bHMIyLSIyzL4kcXXMm9ub8mYixOt9+g4tFLNXIh3aZq/TIA/Gn7OJyke3WqWDQ1NXHOOefw4IMPkpOTE+tMIiI9IiPZy/kX/5p7Mq/GNhYnB1/ljbsuxKhcSIx9urGOzJYNAKQWD3E2TDfrVLG47LLLOPHEE5k6dep3PjcQCOD3+3faRETiRZrPw5W/vJk5w34LwNGNz/LEn69wOJX0NovL6xhibQJgn6G9c9LmFzpcLJ544gkWLFjAjBkz9uj5M2bMICsrq30rKSnpcEgRke521FlXcF/KzwA4u+kfbJj9V4cTSW/SsHUVmVYLIctLv8EHOB2nW3WoWFRUVHDFFVfw6KOPkpycvEevuf7662loaGjfKioqOhVURKS7HXvhrdwTPg2AAR/exPNPzXI2kPQa3solAPgzh4Db63Ca7tWhYvHpp59SVVXFuHHj8Hg8eDwe3nnnHe6++248Hs8ub/Dj8/nIzMzcaRMRiUdlfdIY8P3pvOSeissyHLnsBlYvne90LOkFilpWANDaZ6TDSbqfpyNPPuqoo1iyZMlOj51//vkMHTqUa6+9Fre7991MRUT2LqeO7Q+jHmfJ7w9jlL2Ctqe/T3PBu6T1Heh0NElgA4NrAAj27f1XUnZoxCIjI4ORI0futKWlpZGXl8fIkb2/hYnIXsKTxMMDfscKu4R8q54N95yM3dbkdCpJUC8s3MS+4WixoGh/Z8P0AK28KSKyC784aRIXBX9FjclkhGsjb0w/lTkrtjodSxLQH596k2yrmaBx4y0a4XScbtflYvH2228zc+bMGEQREYkfZX3SeH/GNO7IvImA8XCsez4LHr3J6ViSgMZY0dGKz80A0tPSHE7T/TRiISKyG5Zl8ZtLL+D60EUAXOl5hkefesLhVJJoxrqixWKBvR9pvg5NbUxIKhYiIt8iK8XLZVf9hmcih+C2DMcsvx6aa5yOJQlkrGs1AAvtfUny9P7Dbu/fQxGRLhrUN52RFz3IGruYfGpZOPMHGPubl9eLfJ0JtTHC2gDAQrOfs2F6iIqFiMgeGDKwmMdLb6fF+BgbWsimN+91OpLEOWMMyxd+gM8Ks91kcPTkiU5H6hEqFiIie+iqc07jD+EfApDzwe0sXvqZw4kknr2+vJJ/v/AcAEus/bjppOEOJ+oZKhYiInso3edh+Gm/Yp49mHSrDfPiFboTquzW3+asaZ+4mbbPJCzLcjhRz1CxEBHpgDMnDCRwwt20GS9jggtY8uJfnI4kcWrf/HTG7rjUdL8DpjicpueoWIiIdNDBEw/ilfzoJaiDF8+AmjUOJ5J4lNlSQYmrmghusvc7yOk4PUbFQkSkgyzLYsJZN/FBZATJJsCiu89gzdY6p2NJnBlU9wEA2/uMB1+Gw2l6joqFiEgnlOSlc3/eNTSYVMa41rH86d86HUniTGlr9KadjcWHOJykZ6lYiIh00qzLT2Om7+cAHLv9UT77bIHDiSRuGMPQ4HIA7H7jHQ7Ts1QsREQ6ye2yuPm6m1mafAA+K0TS7GvBGKdjSRzYsHIhfaklYLz0GXKw03F6lIqFiEgXWC4XzUfdQcB4GNr8CWveedTpSBIHZr/4GADLvSPIyc5yOE3PUrEQEemi8eMO5JWsswDIefcWCDQ6nEic1BaKsF/TfAA8g49yOE3PU7EQEekit8vi4POns9EUkGdvp/LFW5yOJA5aXlHNQVZ0fsXIQ09zNowDVCxERGIgPyeb1wb8CoC8ZbPwr9dEzr1V/coPSLUC1LtysApGOh2nx6lYiIjEyA/PPo+3XJPxYFP1+KUEQiGnI4kDfOXvAFCePQFce99hdu/bYxGRbpKdmkTLlNtpMsnsG1zB60/+3elI0sOCYZu8yujCWI39DnM4jTNULEREYujkQ8ezYMB5AIxfew8m1OpsIOlRC1asYXBkLQBDDz7V4TTOULEQEYmxCWfdxDaTS5GpZvPruknZ3mJzfSuPPv4PXJZhi28f8goHOB3JESoWIiIxlpKWwRtF0RU5s+ffTbix2uFE0hOufnIRh7iiy3jXFe5di2J9lYqFiEg3OPqsy1lBGemmmQ3P6vLTvcHH67dzqDtaLMJle89t0r9OxUJEpBsUZqeycvSvARi4/klM3UaHE0l3G+6tpJ+1nYDxkr7foU7HcYyKhYhINzn0mO/zoT0SL2Eqnr/V6TjSzaZ6FwPwiT2Efvl5DqdxjoqFiEg3yUv3sW701QD02/g8kerVDieSbmMMZ9qvARDY93iSvW6HAzlHxUJEpBudfvKpzGEcbmw+ffgajO5+2isFyufTn0qaTDJjTrnM6TiOUrEQEelGaT4PkcNuAODA5jlUrJjncCKJpca2ECfe/R7/9+DdALxt709edrazoRymYiEi0s2mHjmVD5MPByD05u0Op5FYem7hZlZsqedE18cAvB6ZgGVZDqdyloqFiEgPaD34GiLGYlDtu2xa8q7TcSRGgmGbw1yfUeqqpMGkMmDy95yO5DgVCxGRHjDl4EN4N3UqABGNWvQaEdtwjCt6emtO0uH8z3FjnA0UB1QsRER6gMtl0TjxlwSNm4ENn1C95E2nI0kM1Da1cZR7IQCbC6bg8+y9V4N8QcVCRKSHTB5/AE9EjgQg8tZ0h9NILGRWzaPAqqfJJHPEMac7HScuqFiIiPSQPuk+QpOvImjcFNYvoO5zzbVIZEs2NbDvun8CUNHvBEYMyHc4UXxQsRAR6UFTJuzPM5HDAKh4cbrWtUhgP33oHQ5zfQZA8uSfO5wmfqhYiIj0oH36prP/D28mYixGt8xl0cf/dTqSdEIgHGFS4ENSrCAb7AL6D53gdKS4oWIhItLDho86gM9yjwEg/f0ZDqeRzqhrDnGm+x0AWkeehVeTNtupWIiIOKBq3NUEjZv9muaxeeFsp+NIB/3l6deZ5F6OjcWwY3Ua5KtULEREHNCvbBiP77hCJDj7FtBci4Rh24biDc8A8G5kNGT1czhRfFGxEBFxwOCCDP4aPp0W46OsbQWtS//jdCTZQ3VNrfzAHb2i56nI4Q6niT8qFiIiDkjyuHj7tz/kKfeJADS8dDPYEYdTyZ74/MMXKLJqqTPpvGmPczpO3FGxEBFxSJrPw+gf3kyDSaUwsJ71cx52OpJ8h3XVTTR88P8AeD5yMEG8DieKPyoWIiIOOmBIGS+knQGA6507qKxrdDiR7EpTIMzLn23l3kce4bgd9wZ5MjKF/3feeIeTxZ8OFYt7772X0aNHk5mZSWZmJpMmTeLVV1/trmwiInuFrCN+QY3JZKCrik9f/LvTcWQXpr+8nMse+5QL/PfhsgxPhQ/njkvP5sihBU5HizsdKhb9+/fnjjvuYP78+cyfP58jjzySU089lWXLlnVXPhGRXu+UCfvxTEp01GLU2gdpbG5xOJF83eOfVHCQawXDXOW0GS8tR9zKmJJsp2PFpQ4Vi5NPPpkTTjiBwYMHM3jwYKZPn056ejpz587trnwiIr2eZVkcN+16qk0mJa5qaj54xOlI8jUWNjd4/gXA05HDOfOw0Q4nil+dnmMRiUR44oknaG5uZtKkSbt9XiAQwO/377SJiMjOBhb15a3cHwGQ9vFdREJBhxPJV52VPJfRrvU0mRQO/en/kprkcTpS3OpwsViyZAnp6en4fD4uvvhinnvuOYYPH77b58+YMYOsrKz2raSkpEuBRUR6q4YRP6baZJIfqWTBfzTXIl40+P38wjwOgPeIX1E6sNTZQHGuw8ViyJAhLFq0iLlz53LJJZcwbdo0li9fvtvnX3/99TQ0NLRvFRUVXQosItJbnT5xP+4LnwxA2Yr7IBJyOJEAbH/zLvpZ29lKH3yHXOZ0nLjX4WKRlJTEvvvuy/jx45kxYwb7778/f/nLX3b7fJ/P134VyRebiIh8U35GMmNOu5pqk0mf0Fbq5/7D6Uh7NWMM9748l/zF0dGjZ3MvBG+Kw6niX5fXsTDGEAgEYpFFRGSvd8zYMp5M+j4Agf/+QaMWDnp7ZTXBj+4n3Wpjsb0PyWN/6HSkhNChYnHDDTfw3nvvsWHDBpYsWcKNN97I22+/zTnnnNNd+URE9io+j5tDf3Qt1SaTgsg2Vr080+lIe63Fy1dwvvs1AAIHXsqFhw5yOFFi6FCxqKys5Nxzz2XIkCEcddRRfPzxx7z22mscffTR3ZVPRGSvs39ZEW8UXARA8YK7ME3VDifa+xjbZsLy35FptbDGO5gJx5/ndKSEYRnTs/fq9fv9ZGVl0dDQoPkWIiK7Ud/UyuY/HsQIawO1Q84i9+z7nY60V3nx4T9yyobfETRutp01mwHDJjgdyXF7evzWvUJEROJQdnoKswf8MvrrlU/StP4ThxPtHRpaQ9z+z1c5dv0dAPwtfBr9h+h+IB2hYiEiEqdOOPE0XjSH4sKw6V+XY0d0W/XutLWhlf1/O5tRq+7GZ4X5KDKcwy66E5fLcjpaQlGxEBGJU0MLMyn6wZ00Gx9DwytY+PIDTkfq1V5buo0fu9/kNPeHAGyecC3jyvo6nCrxqFiIiMSxCaNG8FH/CwEYuOBOCOi26t3h0421PPXSq9zkeRSApzOnceJxJzucKjGpWIiIxLmJZ9/IBlNIH+pY+vhNTsfplc679y3+7p1JshViW/6hnHHlTFKS3E7HSkgqFiIicS4jPZ1/ZV8MwJANjxKqXOlwot6jLRThpQUb+Kv3bspclWwyfag95q/g0uGxs/SdExFJAD+98BL+GxmDlzC1z1wNPbtSQK9U1xzk5Jlz8D53IYe7P6PF+Lg0eAWlA/o7HS2hqViIiCSA/MxkNoy/iYDxUFD1Ps2fveB0pIS2clsjB97+Kv/j/xPHuucTMF4uCv2Sz8wg3RK9i1QsREQSxJnHTeFZ32kAhJ6/glDDNmcDJahtDW1Mm/kcTyXdxinujwgZNxeHrmTfiSfy2E8nOh0v4alYiIgkiHSfh6zjb2KFXUK2qefz+36iUyIdsHF7M3M+r+T+P/yKt3y/YqxrDQ0mlUtCV1JTdAS3nTqSyYP6OB0z4alYiIgkkKNGDeDevOsJGC+jWj9mybN3Oh0pIayrbuKCmc8Q+Nc53OL9J2lWgHn2YP7Q7x6GH/FD7v3xAU5H7DVULEREEojP4+buK87h9X6XATDssztZ+8GzDqeKX1X+Nu5/fSErHvo5r7qu5Dj3PAD+EPohZwZvJqNkJFcfM4T+OakOJ+09NENFRCQBjT/zWp7530/5vvs9it64hOZ+A0gr1T0tvurnD3+IZ9Wr/NrzBANdVWDB2rQD8B98A6G6fhxW2cTPD9vH6Zi9ju5uKiKSoKrq/KydeTyTrKVsJ4eas19hyJDhTsdyRDhi88n6WsaX5vLu59t4d/bTnNPwAENcmwDYZPpwXfjn3HL5JexXkOFw2sS0p8dvjViIiCSo/JxMHhl7FzkLLmCoq4Lax86g5hf/pU/fAqej9SjbNtz6z9kEVv+XgOtjDnStYqrVCi6oN2m0jTqHBf3P58rCQpWKHqARCxGRBFbdGOB///0WV264lEKrjsX2PpT+z0tk9e3ndLSY2lDTTJLHRUswwvKtflK8bsprW0ja+C4HrL+PEeHlOz3fb1J4JnIYBafcwgkHjnAode+yp8dvFQsRkV5g/ifvU/byWeRZjTQkFZA17Qnol1hXOhhjsKxv3qK8oTXE/r99HQubfT3VHGM+YqxrNWXWNga5tgIQNi42JQ9mccpEHqgcQvqA/fnbuRPok+7r6d3otVQsRET2Mn954mVOWv5LBrm2EjBe/l10NaVTf8bB+8Z2bQY7YlP+XjmNWxvJKMpgwKEDcLk7d5FhMGxjMKyrbubsB+dyzPACfnfaKBZV1PPnN1YyKKWZ5A1vMiy4jGNd88iwWnd6fcRY/NscSd6Jv2HqxLGx2D3ZDRULEZG9jDGGm5/8kMOW3cTR7gUAzLcH83rKCSzxjuL3045jdVUTU4bm4+1kEVjx7Apeu+I1/Jv87Y9l9s/kuL8cx7DvDSMYtvG6rfaRB2MMgbDNMws2kZbk4ZT9i6ltCWLbEV58400+/HQxB7pWso+1hSyrmRbjI91qJZdG8iw/2VbzNzKstPvzhj2Oj+1h/PLskxgyZLjuRNoDVCxERPZSj83dwNb/3M7/eJ4jyYq0P77BLuATeygLzb6MP+BA+g07kBSCpCT7WF4HB5QW0D8nBZcrWgqCYZsXF29hcEE6FbWtvHT/PArvXQhfP2pY0QVAK38+gvV5daTaTRzct5Uky6bv9nmMc60m02rGhSGZII2kkEHrN0Yfduczu4z37FF8YI8kpXQCczcFaQ1F+PC6oyjMSo7Vt02+g4qFiMhezBjDOXe9wIG1LzDVtYChVjkey97t8yPGopIctpo8AqnFNHpyaG5twxusp8zaRpOdzH/vPopQYxLwzXkQYMjMbOSKKx7C5dqzw0qz8VFlslluBvKxPYxak8lBJcksropQ3pZGDZlcecpkVjR4yE71srqyiRtOGEYgbNPYFtIVHj1Ml5uKiOzFLMvith8fxWtLR7AmJ5UfPvkRlw/ciG/zXAZalYxwbSTfqidiLNyWwW0Ziqml2KqFttVfvtGOMwwbyvsTavy2iZAWfn8mqzaWUlhaxUpTAsBqBmCXHckRB45l2dZGXv28gUhrPekZmUw9eBJHjyph5dJtLH9vHXf+YDSD+qbzY+D91TXkpiUxvDiTk3fxaRqpiF8asRAR2QtU+dvom+HjrRVVPLdoM+dOLGFYrotlNTaBcIQD8oI8/MoHbKlYQ3rbNnItP4OLcklOz+bRlRZpy2yyXvzueQwH/e04/tTWxnEjCzn3oIHkZ6oA9BY6FSIiIp3W0BoiK8ULwNsrq2icv5UFP37+O183bc40So8o7d5w4og9PX7rJmQiIvINX5QKgCOG5HPiWaPI7J+56+kVABZklmQy4NABPRNQ4paKhYiIfCeX28Vxfzku+sXXy8WOr4+beVyn17OQ3kN/AkREZI8M+94wzvz3mWT223kYPLN/Jmf++0yGfW+YQ8kknuiqEBER2WPDvjeMIacOidnKm9L7qFiIiEiHuNwuTdCU3VLFFBERkZhRsRAREZGYUbEQERGRmFGxEBERkZhRsRAREZGYUbEQERGRmFGxEBERkZhRsRAREZGYUbEQERGRmOnxlTe/uEu73+/v6Y8WERGRTvriuP3FcXx3erxYNDY2AlBSUtLTHy0iIiJd1NjYSFZW1m5/3zLfVT1izLZttmzZQkZGBpb19Xvvdp7f76ekpISKigoyMzO/+wUJqLfvo/Yv8fX2fezt+we9fx97+/5B9+2jMYbGxkaKi4txuXY/k6LHRyxcLhf9+/fvtvfPzMzstX9YvtDb91H7l/h6+z729v2D3r+PvX3/oHv28dtGKr6gyZsiIiISMyoWIiIiEjO9plj4fD5uueUWfD6f01G6TW/fR+1f4uvt+9jb9w96/z729v0D5/exxydvioiISO/Va0YsRERExHkqFiIiIhIzKhYiIiISMyoWIiIiEjMqFiIiIhIzva5YvP3221iWtctt3rx5TseLqZdffpmJEyeSkpJCnz59+N73vud0pJgpLS39xs/vuuuuczpWtwgEAowZMwbLsli0aJHTcWLmlFNOYcCAASQnJ1NUVMS5557Lli1bnI4VExs2bODCCy+krKyMlJQUBg0axC233EIwGHQ6WkxNnz6dyZMnk5qaSnZ2ttNxYuLvf/87ZWVlJCcnM27cON577z2nI8XMu+++y8knn0xxcTGWZfH88887kqPXFYvJkyezdevWnbaLLrqI0tJSxo8f73S8mHnmmWc499xzOf/881m8eDEffPABP/rRj5yOFVO33XbbTj/Hm266yelI3eLXv/41xcXFTseIuSlTpvDUU0+xcuVKnnnmGdauXcsPfvADp2PFxOeff45t29x///0sW7aMu+66i/vuu48bbrjB6WgxFQwGOeOMM7jkkkucjhITTz75JFdeeSU33ngjCxcu5NBDD+X444+nvLzc6Wgx0dzczP77789f//pXZ4OYXi4YDJr8/Hxz2223OR0lZkKhkOnXr5/5v//7P6ejdJuBAweau+66y+kY3e6VV14xQ4cONcuWLTOAWbhwodORus0LL7xgLMsywWDQ6Sjd4g9/+IMpKytzOka3mDVrlsnKynI6RpcdeOCB5uKLL97psaFDh5rrrrvOoUTdBzDPPfecI5/d60Ysvu7FF1+kpqaG8847z+koMbNgwQI2b96My+Vi7NixFBUVcfzxx7Ns2TKno8XUnXfeSV5eHmPGjGH69Om9bpi5srKSn/70p/zzn/8kNTXV6Tjdqra2ln/9619MnjwZr9frdJxu0dDQQG5urtMxZDeCwSCffvopxxxzzE6PH3PMMXz44YcOpeqden2xeOihhzj22GMpKSlxOkrMrFu3DoBbb72Vm266iZdeeomcnBwOP/xwamtrHU4XG1dccQVPPPEEc+bM4Re/+AUzZ87k0ksvdTpWzBhjOO+887j44ot71Sm6r7v22mtJS0sjLy+P8vJyXnjhBacjdYu1a9dyzz33cPHFFzsdRXajpqaGSCRCQUHBTo8XFBSwbds2h1L1TglTLG699dbdTsr8Yps/f/5Or9m0aROzZ8/mwgsvdCh1x+zpPtq2DcCNN97I97//fcaNG8esWbOwLIunn37a4b3YvY78DK+66ioOP/xwRo8ezUUXXcR9993HQw89xPbt2x3ei2+3p/t4zz334Pf7uf76652O3CEd/Xt4zTXXsHDhQl5//XXcbjc/+clPMHF8F4HO/DuzZcsWjjvuOM444wwuuugih5Lvuc7sY29iWdZOXxtjvvGYdE3C3CukpqaGmpqab31OaWkpycnJ7V/ffvvt3HPPPWzevDkhhl/3dB8/+ugjjjzySN577z0OOeSQ9t+bOHEiU6dOZfr06d0dtVM68zP8wubNm+nfvz9z585l4sSJ3RWxy/Z0H8866yz+85//7PQPWiQSwe12c8455/DII490d9RO6crPcNOmTZSUlPDhhx8yadKk7orYJR3dvy1btjBlyhQmTpzIww8/jMsV//9X68zP8OGHH+bKK6+kvr6+m9N1n2AwSGpqKk8//TSnn356++NXXHEFixYt4p133nEwXexZlsVzzz3Haaed1uOf7enxT+ykPn360KdPnz1+vjGGWbNm8ZOf/CQhSgXs+T6OGzcOn8/HypUr24tFKBRiw4YNDBw4sLtjdlpHf4ZftXDhQgCKiopiGSnm9nQf7777bn73u9+1f71lyxaOPfZYnnzyybguTl35GX7xf5hAIBDLSDHVkf3bvHkzU6ZMaR8xTIRSAV37GSaypKQkxo0bxxtvvLFTsXjjjTc49dRTHUzW+yRMseio//73v6xfvz5hToN0RGZmJhdffDG33HILJSUlDBw4kD/+8Y8AnHHGGQ6n67qPPvqIuXPnMmXKFLKyspg3bx5XXXVV+7oIvcHX9yM9PR2AQYMG0b9/fycixdQnn3zCJ598wiGHHEJOTg7r1q3j5ptvZtCgQXE7WtERW7Zs4YgjjmDAgAH86U9/orq6uv33CgsLHUwWW+Xl5dTW1lJeXk4kEmlfZ2Xfffdt/zObSK6++mrOPfdcxo8fz6RJk3jggQcoLy/vNXNjmpqaWLNmTfvX69evZ9GiReTm5vbsv52OXIvSA84++2wzefJkp2N0m2AwaH75y1+a/Px8k5GRYaZOnWqWLl3qdKyY+PTTT83EiRNNVlaWSU5ONkOGDDG33HKLaW5udjpat1m/fn2vutz0s88+M1OmTDG5ubnG5/OZ0tJSc/HFF5tNmzY5HS0mZs2aZYBdbr3JtGnTdrmPc+bMcTpap/3tb38zAwcONElJSeaAAw4w77zzjtORYmbOnDm7/HlNmzatR3MkzBwLERERiX+JcVJQREREEoKKhYiIiMSMioWIiIjEjIqFiIiIxIyKhYiIiMSMioWIiIjEjIqFiIiIxIyKhYiIiMSMioWIiIjEjIqFiIiIxIyKhYiIiMTM/wccvAc985POBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from training import train\n",
    "from nn import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from find_lr import find_lr\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "\n",
    "model = Model(vocab)\n",
    "\n",
    "optimal_lr, min_loss, lres, losses, smoothed_losses = find_lr(model, Loader(trn), lambda lr: torch.optim.AdamW(model.parameters(), lr=lr), return_info=True)\n",
    "\n",
    "print(f\"{min_loss=:.5f}\")\n",
    "print(f\"{optimal_lr=:.5f}\")\n",
    "\n",
    "lr = optimal_lr\n",
    "\n",
    "plt.plot(lres, losses)\n",
    "plt.plot(lres, smoothed_losses, c=\"tab:orange\")\n",
    "\n",
    "# Plot the point where the loss is minimal\n",
    "plt.scatter(np.log10(optimal_lr), min_loss, c=\"purple\", zorder=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9c13c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model has loss 4.554506301879883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 174.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training: 2.4669556617736816 validation: 2.5057549476623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 181.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training: 2.4644272327423096 validation: 2.5106253623962402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 175.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: training: 2.457030773162842 validation: 2.5061471462249756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 180.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: reducing learning rate of group 0 to 7.7475e-02.\n",
      "Epoch 3: training: 2.455885171890259 validation: 2.512030601501465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 185.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: training: 2.456085205078125 validation: 2.5107994079589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 184.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: training: 2.4563632011413574 validation: 2.5043084621429443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 185.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 3.8737e-02.\n",
      "Epoch 6: training: 2.4594452381134033 validation: 2.5054478645324707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 120.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: training: 2.449397563934326 validation: 2.5047760009765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 199.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: training: 2.4583797454833984 validation: 2.508673667907715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 194.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: reducing learning rate of group 0 to 1.9369e-02.\n",
      "Epoch 9: training: 2.4507386684417725 validation: 2.509722948074341\n",
      "Best achieved validation loss: 2.5043084621429443\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "import os\n",
    "\n",
    "\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "\n",
    "model = Model(vocab)\n",
    "model_name = \"bigram\"\n",
    "\n",
    "if not os.path.exists(f\"models/{model_name}.pt\") or True:\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2, factor=0.5, threshold=0.05, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    loss_trn, loss_val = train(model, optim, Loader(trn), Loader(val), epochs=10, validate_freq=1, lr_scheduler=lr_scheduler, num_evaluations=10, device=\"cuda\")\n",
    "\n",
    "    epochs_ = torch.arange(len(loss_trn)) * 10\n",
    "    plt.plot(epochs_, loss_trn, label=\"Training loss\")\n",
    "    plt.plot(epochs_, loss_val, label=\"Validation loss\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"models/{model_name}.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Loading model from file.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f\"Validation loss: {torch.tensor([model(batch, return_loss=True) for batch in Loader(val)]).mean().item()}\")\n",
    "\n",
    "# Now let's save it:\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/{model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1c2c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellofu ay IIn eald Clloimeabs bind mechithisur ig wen.\n",
      "n;\n",
      "Agheyougant\n",
      "Nurninorak' ht ste ithunghe You l tou wim thethesan bur sth t r therean oile, ans f we in, w ave Nakn tathtll d amarid ld\n",
      "\n",
      "\n",
      "\n",
      "Wail se wn vet I'eeck y y mofowevende do omef beld t toowan, s t bedeednere, f he Se hourom m m'schis bif ou meansol d ecaneld thithal felde bus theis, bllmis whey y maina-stharidill,\n",
      "INIfrderteen.\n",
      "TI pleces ot omy pppow--\n",
      "S:\n",
      "Weriesch STha; tr w on indyour al adyorlf s ge grein m t imave go od thang bef thar Whewele farel-pll ind,\n",
      "I a\n",
      "QUSellst ith, yotr anct I tount f BESBO:\n",
      "PAD:\n",
      "NIO:\n",
      "LY: hend s ssertoord ce ING bes deme wnghine. IOFos:\n",
      "nos thavencolwsen, cand t l\n",
      "\n",
      "\n",
      "\n",
      "s hind b yser prow p,\n",
      "ABOLLOLAnesharoupsesade ither thinchof ea camars oaken? r d Prefo h br teatoond te:\n",
      "SCALAnts me a HESICarat t peamperIOFin win ashouithe t, K:\n",
      "VENGRecon:\n",
      "TOLLAD:\n",
      "Yoor tesove h s lotend. m thust nangreavadvepsthaknthat\n",
      "\n",
      "HAureean tod at: LOORY:\n",
      "burey, yos\n",
      "feesee wilanth he in we, moith makJonotoorpllyofalCis maris g\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embed): Embedding(65, 65)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "print(model.generate(\"Hello\", 1000))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2a7f9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m0\u001b[39m)  \u001b[39m# For reproducibility\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m Transformer(vocab, block_size, embed_size\u001b[39m=\u001b[39membed_size, num_heads\u001b[39m=\u001b[39mnum_heads, num_blocks\u001b[39m=\u001b[39mnum_blocks, dropout\u001b[39m=\u001b[39mdropout)\n\u001b[0;32m---> 11\u001b[0m optimal_lr, min_loss, lres, losses, smoothed_losses \u001b[39m=\u001b[39m find_lr(model, Loader(trn), \u001b[39mlambda\u001b[39;49;00m lr: torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdamW(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49mlr), return_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmin_loss\u001b[39m=:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moptimal_lr\u001b[39m=:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/nano-gpt/find_lr.py:19\u001b[0m, in \u001b[0;36mfind_lr\u001b[0;34m(model, data, Optim, lre_min, lre_max, size, return_info, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39mto(device), return_loss\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     20\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from training import train\n",
    "from nn import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "from find_lr import find_lr\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "\n",
    "model = Transformer(vocab, block_size, embed_size=embed_size, num_heads=num_heads, num_blocks=num_blocks, dropout=dropout)\n",
    "\n",
    "optimal_lr, min_loss, lres, losses, smoothed_losses = find_lr(model, Loader(trn), lambda lr: torch.optim.AdamW(model.parameters(), lr=lr), return_info=True, device=device)\n",
    "\n",
    "print(f\"{min_loss=:.5f}\")\n",
    "print(f\"{optimal_lr=:.5f}\")\n",
    "\n",
    "lr = optimal_lr\n",
    "\n",
    "plt.plot(lres, losses)\n",
    "plt.plot(lres, smoothed_losses, c=\"tab:orange\")\n",
    "\n",
    "# Plot the point where the loss is minimal\n",
    "plt.scatter(np.log10(optimal_lr), min_loss, c=\"purple\", zorder=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bd56d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): Embedding(65, 384)\n",
      "  (pos_embed): Embedding(256, 384)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (4): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Block(\n",
      "      (heads): MultiHead(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (keys): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (queries): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (values): Linear(in_features=384, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ff): FF(\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm_pre_heads): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_pre_ff): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (logits): Linear(in_features=384, out_features=65, bias=True)\n",
      ")\n",
      "Total number of parameters: 9901121\n",
      "Initial model has loss 4.720690727233887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:34<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training: 2.545942783355713 validation: 2.5884814262390137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 14/54 [00:09<00:27,  1.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m3e-4\u001b[39m)\n\u001b[1;32m     16\u001b[0m lr_scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optim, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, threshold\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m loss_trn, loss_val \u001b[39m=\u001b[39m train(model, optim, Loader(trn), Loader(val), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validate_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, lr_scheduler\u001b[39m=\u001b[39;49mlr_scheduler, num_evaluations\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     20\u001b[0m epochs_ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(loss_trn)) \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     21\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs_, loss_trn, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/nano-gpt/training/training.py:54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optim, trn, val, epochs, validate_freq, lr_scheduler, checkpoint_freq, checkpoints_dir, restart, project, run_name, use_wandb, num_evaluations, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(trn):\n\u001b[1;32m     52\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 54\u001b[0m     model(batch\u001b[39m.\u001b[39;49mto(device), return_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     55\u001b[0m     optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     57\u001b[0m \u001b[39m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "import os\n",
    "\n",
    "\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "\n",
    "model = Transformer(vocab, block_size, embed_size=embed_size, num_heads=num_heads, num_blocks=num_blocks, dropout=dropout)\n",
    "model_name = \"transformer\"\n",
    "\n",
    "# Print the model and total number of parameters\n",
    "print(model)\n",
    "print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "if not os.path.exists(f\"models/{model_name}.pt\") or True:\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, threshold=0.02, verbose=True, min_lr=1e-6)\n",
    "\n",
    "    loss_trn, loss_val = train(model, optim, Loader(trn), Loader(val), epochs=100, validate_freq=1, lr_scheduler=lr_scheduler, num_evaluations=10, device=device)\n",
    "\n",
    "    epochs_ = torch.arange(len(loss_trn)) * 10\n",
    "    plt.plot(epochs_, loss_trn, label=\"Training loss\")\n",
    "    plt.plot(epochs_, loss_val, label=\"Validation loss\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"models/{model_name}.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Loading model from file.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f\"Validation loss: {torch.tensor([model(batch, return_loss=True) for batch in Loader(val)]).mean().item()}\")\n",
    "\n",
    "# Now let's save it:\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/{model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANDREW:\n",
      "Ay, lady and Saint Hath her hath do say breasts.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "O, Marcius, Speak now, I pray King Edward,\n",
      "Not Rivers, or and falseher from their should cryself,\n",
      "That slain, which thy heart lords, they we are,\n",
      "Doom'd you knowledge him and informent canscure,\n",
      "Which she was in my head, he is Rome son,\n",
      "And with Glouce thus never vengeance, go,\n",
      "And, therefore I drop asparess not so false\n",
      "Of the queen's Richard vow on that shall we heard\n",
      "The sights of love of A west she return'd\n",
      "Either of York strike prince by the fortune,\n",
      "That your father draps traitor's newl-belly,\n",
      "Let's this benefle's in our knighter'd wings,\n",
      "And from 'general them wondering clock,\n",
      "Play \n",
      "In find me have, those is't love us 'burbs;' therefore\n",
      "The sweether in the while-king, when they thrown\n",
      "My stummer's knife my son: prayers, I'll meet them boys,\n",
      "But I'll not slow am hands: things you much\n",
      "And makes not to a fail the bower and more.\n",
      "\n",
      "PAULINA:\n",
      "Why, sweet have so you other heart:\n",
      "And, if I hadly truth, fair of diable to \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(model.generate(\"ANDREW:\", 1000))\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "10ad58ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sacred flames will he\n",
      "grave e'er forth from his crustion!\n",
      "\n",
      "FLORIZEL:\n",
      "Nay, how now she insing that,\n",
      "A debiest sendly-beat's blones, must new or teed.\n",
      "\n",
      "ROMEO:\n",
      "Be sight shall fight; but where it the bates took old?\n",
      "We will the revolt! what not, thou mightle,\n",
      "Graze I to know it you son and judgman\n",
      "I am by thy meeding wills so desping:\n",
      "My why cirs, followers, I not may your honour's,\n",
      "Orld nothing poor Richard spirits; you must take yond\n",
      "He warms, for what you way. You he's cousin,\n",
      "Of that person thus oldied? where nows in hone?\n",
      "\n",
      "spend! Seem on this house, you will no.\n",
      "\n",
      "All:\n",
      "Ay, my sene fathere.\n",
      "\n",
      "LUCIO:\n",
      "Yound he came; it is no lion, withart is mistrage,\n",
      "Marry, With hit prison well; what look gleet's you king\n",
      "Jove in o' Kish Rome! No, how now! you bower,\n",
      "A man; but sointed in the shoulds of the eighted torth\n",
      "\n",
      "Third Watchmandan: farest you must\n",
      "To the goding: all him, famity, fair hears:\n",
      "The fiery the will is suburr'd the lawful of chee!\n",
      "\n",
      "EXETER:\n",
      "I chall go, I'll can dear his day.\n",
      "\n",
      "JULIET:\n",
      "Notest Inwar;\n",
      "Mong the Duke of Northumberland appeal'd,\n",
      "Harry answer in eviefer her rands.\n",
      "\n",
      "CLARENCE:\n",
      "There wild,\n",
      "And a deare's dishems doth vail speak?\n",
      "\n",
      "CAMILLO:\n",
      "Marget, that he dare an fool-maked--which Lord:\n",
      "And god before, he is night so me,\n",
      "To wept to greak me, provison with our gence,\n",
      "That firming odward the gandlent's lings of cert\n",
      "Than Henry Duke of Nown, why woes't and a to day;\n",
      "Nine senate flow biled of youndering he reast.\n",
      "\n",
      "EDORD:\n",
      "Which the noble thine world, and the vail, thy prevent,\n",
      "Or water engtle Richard home as mine, trifled\n",
      "Your proming on executed! Those\n",
      "Cward it waship in gapveron,\n",
      "Suffer he welcof lords and from the Roland?\n",
      "\n",
      "DUKE OF GAUDIT:\n",
      "All helposed his consquence in this sug Lenton wart.\n",
      "\n",
      "RATCLIFF:\n",
      "Farewell,\n",
      "No sove pay to with the faulthoutst pitch a ch:\n",
      "Upproace of the rick Henceford? Saventle, I thinked of it.\n",
      "Should be and from him: heavous assaughts, shall cort\n",
      "His no lose to knowledgely to be blishments.\n",
      "\n",
      "KING RICHARD III:\n",
      "So; since, see, sir,\n",
      "You will't would and gall'd him our divine.\n",
      "This shall be his kindly here court,\n",
      "Brevery not take. Julia, surr'd, along the exentred\n",
      "And my robed, let's from with snain and well,\n",
      "Stake't the versaughem well king; which growing;\n",
      "And if his demight in leighn your sije,\n",
      "His, disown father tears' king.\n",
      "\n",
      "CLARENCE:\n",
      "Men have to much seen\n",
      "Of n a reaveraines to subject.\n",
      "\n",
      "WARWICK:\n",
      "Who it our ground that live with his end within\n",
      "Their strime I honour the winds oath and valio\n",
      "Where speeding last, and as store of thy thamble.\n",
      "\n",
      "YORK:\n",
      "No full we thoughts rest\n",
      "Lest tell my daught give me to take lord\n",
      "Thy throws: If love, say, who for him.\n",
      "\n",
      "AUTOLYCUS:\n",
      "It must it a peace wearer. thonour of this speaks,\n",
      "That is not he toward worshal: then my rage as encile\n",
      "His back in the misking he lew to be my heart in myresanus;\n",
      "Becand, I have pronood thereof my trange;\n",
      "By withal, we every a driked isloved\n",
      "Amend for our wish to pass rink.\n",
      "\n",
      "LEONTES:\n",
      "We not worse, by hanged be my one is,\n",
      "Thatuty to reason me to teck.\n",
      "\n",
      "CAMILLO:\n",
      "In so sfore I death thy cheek?\n",
      "\n",
      "AUFIDIUS:\n",
      "'Tis gone! what's us hem?\n",
      "\n",
      "HASTINGS:\n",
      "If you hast say adverisface?\n",
      "We whenes, souls take a racked him, but home:\n",
      "The cuttion more trulth.\n",
      "\n",
      "ANGELO:\n",
      "But is now, ghost it abrigon?\n",
      "\n",
      "WARWICK:\n",
      "Now? come to longs much she durst him! thou dost\n",
      "Gives that royal, of you knowledge, my lieght.\n",
      "\n",
      "\n",
      "AUCHBOLAND:\n",
      "Saint your confitural qualist,\n",
      "And that young be G'Henry namelight call get hus.\n",
      "Gate mens: forgors at well it is,\n",
      "Thou not the wickorn of your sident'st general.s\n",
      "How, are the enied with best.\n",
      "\n",
      "AUFIDIUS:\n",
      "There leand not please that a tapen this light.\n",
      "\n",
      "BRUTUS:\n",
      "They let the cause than whom it. Fifth\n",
      "Is was nothin much thing I would heir churt.\n",
      "\n",
      "KING RICHARD III:\n",
      "Hall upon thine from thy crown.\n",
      "\n",
      "KING RICHARD III:\n",
      "Know, bring to Morgarery poth fortune dry.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I am good be noble you: tell with to cheeken,\n",
      "Are nellish of kite for and straight his this.\n",
      "In does myself Bohen:\n",
      "Fort is prettixe for heads him\n",
      "Was here, shall mene these is chosens to you:\n",
      "butches a sever i' tnow before thy fault\n",
      "That's dancing walker sed to abud spearf--\n",
      "As all I chall my son fortune; but thou, learned,\n",
      "That woo wearite-dared pass the bewn tide of a fallowgs.\n",
      "Are they have matron's; he drocks cause that himself,\n",
      "In thence, partison'steen to duty think\n",
      "Should not a dowter wit.\n",
      "\n",
      "POLIXENES:\n",
      "He man. Come stay plead to alester pleape ton,\n",
      "I high puckor his labs, witt, will that say o' the\n",
      "For ensolver.\n",
      "\n",
      "Nurse:\n",
      "Your serve:\n",
      "Wells him not brine's king, to metha.\n",
      "\n",
      "MERCLIUS:\n",
      "Let the poorbear men!\n",
      "\n",
      "\n",
      "COMINIUS:\n",
      "Woild held,\n",
      "I--Lord, any all.\n",
      "\n",
      "All:\n",
      "It will have for yown marsher, can you: my lord,\n",
      "The wounds, a shall enemies;\n",
      "Ere put of it; will wise? Ladying, peace have thee.\n",
      "\n",
      "HASTINGS:\n",
      "\n",
      "Nurse:\n",
      "Petain, albound on your firm walling\n",
      "Than bears times. Coward Mentague!'\n",
      "Allow have met to be sirrume to his voice.\n",
      "\n",
      "WARWICK:\n",
      "They godsmen.\n",
      "\n",
      "RICHARD:\n",
      "\n",
      "ROTH:\n",
      "Think\n",
      "Save you springs beggares herds; and injustices the\n",
      "hithouseld on Rome on, when forth ire, I'll nobles as by\n",
      "the shight-forgear struch a crept wateful,\n",
      "Scuedilence of fights, if I\n",
      "dreade out sutnifferable that be is thus,\n",
      "Thus have revenge queen.\n",
      "\n",
      "LADY CAPULET:\n",
      "You beast me, or I were not we shall been so king,\n",
      "Peace, ross'd out charce: to have is as bare in\n",
      "The suspleason, with the king high house with he upon\n",
      "Misture false we heavy us\n",
      "Thich sleep in less shakes at in the fight,\n",
      "Where's Clarence, power. I by you afmox\n",
      "Nothing and this is unto liss sucrequies:\n",
      "He did so; you were that we underth him best?\n",
      "\n",
      "Second Petiaten:\n",
      "For a raziler in this coverter\n",
      "enduce tred pitested suit presectorse hill infite,\n",
      "Seem and requal only packlent.\n",
      "\n",
      "BENVOLIO:\n",
      "Stire Menener:\n",
      "O, sir, my lord, like my lagguainst payers.\n",
      "Thou art Some, come, as you talking,\n",
      "Wave have me for give day each so longed little:\n",
      "Mark at Ancius.\n",
      "\n",
      "BRALTHAM:\n",
      "Nay, fare the king our guilty and larms;\n",
      "Let your haves by I have put and you the royal;\n",
      "Bear his your gracious sounds of line,\n",
      "Darector his cerpe, and the stoon strifts, as thou,\n",
      "talk'd, to all love prudh thee way.\n",
      "\n",
      "DUKE OF AURLE:\n",
      "Then George men have made with you.\n",
      "\n",
      "STANLEON:\n",
      "Surrey, my loviel's easted; lore liege by olger.\n",
      "\n",
      "KING RICHARD III:\n",
      "Spray, you shall pridonDeroroud callet up you.\n",
      "Is Kin HENRY BOLISBY:\n",
      "Come merdary. I stand  toward, John;\n",
      "I shake you know, and give to I do it:\n",
      "'fay;' 't is it dead, of whold, I'll know leave the Duke it now\n",
      "may mean: but is my deserverent where,\n",
      "To set our mother fair.\n",
      "\n",
      "KING RICHARD III:\n",
      "Rave you Cant hithers.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "WARWICK:\n",
      "Oncoment or scronge? O Marchman, of have fit,\n",
      "In thy kings-fant: the milk straiges and when Tyrrelen:\n",
      "Or you good Aufidius and myself cridefule.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "Put, bles for if this was will I have verge yourself,\n",
      "She heir no roaner live in deamness.\n",
      "\n",
      "ELBOW:\n",
      "Here daught so does with form their pudon;\n",
      "As he will as the stant, longen glory chains\n",
      "Of I'ld not this so extrempt, his ranged hences,\n",
      "With a thou, liked not dail to thus! O, my lord?\n",
      "Wert tongue'st, look us for thee! where nose or\n",
      "Under a feasty, thence were worl; could more us,\n",
      "One brave me gracipe his discrick,\n",
      "And by privally mights and love noble gild,\n",
      "As him all right, favout wont some for her break,\n",
      "I'll his o'er rogs him.\n",
      "\n",
      "Nurse:\n",
      "My lord, I had good lady;!\n",
      "\n",
      "CORIOLANUS:\n",
      "Come!\n",
      "\n",
      "DORDOS:\n",
      "You blind? nst fault:\n",
      "Ay court me and much in thine shall fight\n",
      "With the makes hand: so it the is swear treators\n",
      "Touch revenge, how thou lark's death so magains,\n",
      "Thou nevel me sweet humb chamen; robey with the\n",
      "seak-flain'd Paring.\n",
      "\n",
      "Third Citizen:\n",
      "Plarged,--with wisdowalful beat the trons,\n",
      "Say's thy night-pleasure upon thy hoath Love;\n",
      "Have letters than or an thy faults: hang born'd\n",
      "but we can misdeed?\n",
      "Were he shall be motion true or to dear: word thy all\n",
      "put uved into shamenhs to by my Raught,--\n",
      "That he me suceber's the new, that art of their lords.\n",
      "Plaise?\n",
      "\n",
      "FRIZEL:\n",
      "To thy such and my lieve.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Rough, I'll do out.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "No, and the grace ission, that was bring 'twaility.'\n",
      "\n",
      "PRIS:\n",
      "As me:\n",
      "There's in presence you washing he hath death,\n",
      "And this madam atter to his love\n",
      "The virgeat up courted.\n",
      "\n",
      "PRINCE:\n",
      "Ay, offency bid you to pass'd in thine,\n",
      "And friends link.\n",
      "How, well: madam, but my bodden an is navour!\n",
      "An though shalt we this night; and in this?\n",
      "\n",
      "HENRY BOLIO:\n",
      "And sure fiends.\n",
      "\n",
      "HERSTING RICORY:\n",
      "Good too distroy in thy heart! not dost, when;\n",
      "And they, on my Rome! O my mepany love love for fance,\n",
      "How will him hastings before. By I be fortaze;\n",
      "Which 'twere I heard, good Enet to much, short\n",
      "But in the herlike of a Rosand spure,\n",
      "Hath saglest much afforth him.\n",
      "\n",
      "HENRY PHERY VI\n",
      "SARET:\n",
      "What, too foold great the best.\n",
      "\n",
      "Second God! Why was arry Vountanuce of Warwick, came?\n",
      "\n",
      "GLOUCESTER:\n",
      "The peace will-loing ladge, to the most intor best,\n",
      "Which at forfewle office them fly his creating;\n",
      "Another libenes in grounds anot's easy;\n",
      "By he war e'sbable the serves pare garl. So will!\n",
      "Dost be win thy life? Prey'st Judget.\n",
      "Go, good anoth melt, my love lady profesy grace,\n",
      "Like me fistiful merry to lids father's deed.\n",
      "Sweet it were this fear's loves enemines\n",
      "Was mine ear thereof, are brother's found of and\n",
      "You jewelloy and for the cank-tanous lain,\n",
      "But neiver me provident, thy sons: beso him,\n",
      "And topt thou such a lie off illiance, from Herefords\n",
      "As I fond to your now yourselves leave: us a read,\n",
      "dancer, sirrs shate where is misselvess agass\n",
      "Consional, alles, I my Romeo;\n",
      "We caugs, beling his for siness wilel:\n",
      "Julbring, and fearful demum unto me,\n",
      "Who'st then hot from heir lovest, came was as mile;\n",
      "On thou comfort, and stroke their counselet,\n",
      "Straight, my patter of myself a stakes.\n",
      "Hath out is, upon more these did it.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Welcome, For your king, pardon, dispassue again.\n",
      "\n",
      "WARWICK:\n",
      "Off when 'twere it is salt a late!'\n",
      "Thus high laughters up from, 'father. HEP a holMIs:\n",
      "My diso consellomes, good be silencor:\n",
      "Uncles the king, you so brave noble true I'll,\n",
      "Take your you fight three youls' loved by fled!\n",
      "Place as your friends, I am most raise.\n",
      "\n",
      "LORD KING HERY VI:\n",
      "Romeo stany, dead, is your grace and\n",
      "By humeling me thee nevermits of your cherle;\n",
      "I know here were is night; yet the Lord ord,\n",
      "Let me palse into a misic.\n",
      "\n",
      "BANGHAM:\n",
      "As my lord.\n",
      "\n",
      "Nurse:\n",
      "You comeonourion, I'll please you; it a sweet,\n",
      "Nor forsolvet did done of matter.\n",
      "\n",
      "ROMEO:\n",
      "If your wiptness she thee your cates you should.\n",
      "\n",
      "ROMEO:\n",
      "At thou! O, a fardedint, sir, he well sleep Romeo,\n",
      "I thinks that while infecty, by the king;\n",
      "And sins had b'd it these kind his to me.\n",
      "I do fwls; it a mountation tonder, that it non\n",
      "The purposiciate in the fire--plant coversh slee\n",
      "My are maggive as was on had over wrong.\n",
      "\n",
      "CORIOLANUS:\n",
      "There mine ears, that is live\n",
      "That off, and hoppine thou wisthought you woest,\n",
      "Or which rathers? yet Gentleman,\n",
      "To spersing to yea,--day.\n",
      "There's heart you out we deposely to put on't.\n",
      "\n",
      "RIVEth:\n",
      "O, like a surel, they pardon or kills,\n",
      "Rich'd by the blows of my part\n",
      "Unfricting sceptioned shen fear\n",
      "And if your nesurnightides shall it him.\n",
      "So more buring\n",
      "And that me is tenderorous.\n",
      "\n",
      "ROMEO:\n",
      "This that, to it smile cition, and not daughter on of\n",
      "Bed like, my tenderiove, ha!\n",
      "\n",
      "PERDITA:\n",
      "Why, soul curse? Come of you have\n",
      "On pitchsame dises, to that bit bettener the\n",
      "For thanings with by the singlehs break of death; and\n",
      "drum of you fearful pitial of successions delling with thy\n",
      "like life.\n",
      "\n",
      "JULIET:\n",
      "Go, grief too asoping hath behold, busins,\n",
      "Tink it our less litter'd shall tell me weason--\n",
      "For thus and the been rie ancients\n",
      "To murderer franshis bearned and pither former:\n",
      "Tear here by my very volried\n",
      "Would to my lord make tyrate to daught be in wer,\n",
      "And if more whether and discure Hastings upon,\n",
      "That must of itsafe?\n",
      "With her abb'stant of the hate.\n",
      "He should not Rome cry.\n",
      "\n",
      "CAPULET:\n",
      "Become torchy creat.\n",
      "\n",
      "CAMILLO:\n",
      "Braw, think I this, what they wept that your bisses;\n",
      "And I'll hopest any country's eyes and piling.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Why, come me in this contreasural in friend.\n",
      "\n",
      "AUTOLYCUS:\n",
      "What cold.\n",
      "\n",
      "VIRGILIA:\n",
      "\n",
      "VERnouracts:\n",
      "How now!\n",
      "\n",
      "BENVOLIA:\n",
      "Think his heart; you shall sidity, no\n",
      "come frend forceive and their great leave,\n",
      "As 'Hope you are on your catches, 'shall. He's gone:\n",
      "No, monthunds, think both you a gentle;\n",
      "You have made builds world, my lumit, my last\n",
      "To see his knowless: the phear, I do my daughter\n",
      "He terrel, so holy look weday strength up.\n",
      "My lords, woman.\n",
      "\n",
      "CORIOLANUS:\n",
      "Live hither me?\n",
      "\n",
      "Poor:\n",
      "'Tis grat's like eyes: the occest and.\n",
      "\n",
      "CORIOLANUS:\n",
      "He housest\n",
      "To the friger her profleme; the god prime may rest,\n",
      "To make your free a bowd, as two king any own\n",
      "To the come much as all; therefore that in the prese,\n",
      "I'll me chyance your life--sBe soure I'll done.\n",
      "\n",
      "SICINIUS:\n",
      "As I must pale my own struck your sorrow;\n",
      "But God death kindry; whereing of be to me,\n",
      "Thou let hummand you, good Glet themberless, as will not parer's very\n",
      "And fintry such on his by lips?\n",
      "\n",
      "BENVOLIO:\n",
      "Of such for somet sir. Wilt;\n",
      "Stand she was that lost? to brief you no,\n",
      "For his wranks, but the prethlext a grace?\n",
      "So cannot an if they do not for\n",
      "Underious?\n",
      "\n",
      "MAMILLIABET:\n",
      "My bid thy take guilling in this neamen:\n",
      "Castion?\n",
      "\n",
      "LADY CATESBURY:\n",
      "My gois bottler's bock thoughtsrowsay!\n",
      "Ah'd nobver the sea-back, by will begguin\n",
      "canser? O they shame I between to o'ere.\n",
      "The idiserved at ipon the fearful and or messe\n",
      "He field: who\n",
      "Treed not\n",
      "Their prove barms gold with the entertain. Well he\n",
      "hidst Ware, thou not down, orne? Ruscond suck, no\n",
      "have the would use all merried, to the furth his heigh,\n",
      "Three well. Henry, hoher! have I had short boke\n",
      "Which cause hand the could off\n",
      "Making Richarders her peern of specioks thyself:\n",
      "Thee labour, ait and true no heaven man eleving?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "More daken the should in there, thinken\n",
      "And thereif a wail he for powert good: Clucks.\n",
      "\n",
      "LEONTES:\n",
      "What ceitle his that your highness wofe,\n",
      "Romeo friend to rest be off and intement: ho!\n",
      "art flest, pity! ever so now doom I houraffled;\n",
      "Show when how I have join or an girage.\n",
      "\n",
      "KING RICHARD II:\n",
      "Whill come and my know to--dind by?\n",
      "Not young, this that bless spake thy snelling?\n",
      "Is my lick an in yourself here wretchy!\n",
      "\n",
      "BENVO:\n",
      "Why, let in can this nextair else shall me\n",
      "By this virtuouted.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Then peace in Gatentle greate villian:\n",
      "Had, am I innot.\n",
      "\n",
      "LADY ANNE:\n",
      "But thou givest me may to advisons marves:\n",
      "I'll have, in heaven surp you,\n",
      "I pray you, for news,---God you think this torance,\n",
      "Shall I fell eve his liege. Brough the manning to\n",
      "I will angin thy over hange them; let images\n",
      "awake thy fathers place standed that title hath\n",
      "To exectful and kew the impoicest and from honour,\n",
      "Which ousin arms to with cursed and Edward in me\n",
      "Varelace for a basts of your holyight:\n",
      "You will must next mine as Gold all than now,\n",
      "The ferm'd in my else? knees these haver 'sage,\n",
      "And infiviated with your head oath,\n",
      "No almucked, but in bleen comfort of slaup,\n",
      "Not do to be the angely Northoughth.\n",
      "Stunou, brave you hear to York, I page\n",
      "The naturation of my worthin, swards, will wear;\n",
      "We'll have tord he his sidile?\n",
      "\n",
      "SICINIUS:\n",
      "Where comes that hom here?\n",
      "\n",
      "SICINIUS:\n",
      "Go, less no more of my life?\n",
      "\n",
      "FROTH:\n",
      "We sung other cills, and master the father of woman\n",
      "to his putify in praised with me his she wome them vain.\n",
      "\n",
      "GLOUCESTER:\n",
      "Come place, mark of Earl then honound a dead.\n",
      "\n",
      "MENENIUS:\n",
      "Where's for thou, that kill's I be meet to me.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "ANurse:\n",
      "What is thatShout you ded.\n",
      "\n",
      "CLARENCE:\n",
      "Pade help you our soppeeciest secried:\n",
      "Now thou dost that tuty have for heard.\n",
      "\n",
      "LADY CAPULET:\n",
      "What, why is day? sistrangle? Yet, ray--Yorshould: papewer, God,\n",
      "Sents, bleard, when yet will read up him.\n",
      "\n",
      "HASTINGS:\n",
      "Becalf with all trust with the insign therere,\n",
      "All my soul of the Duke of Norfolk,\n",
      "Then rave from banishel'd King Ratial.\n",
      "\n",
      "GLOUCESTER:\n",
      "Eeforming war thou becomp, for that, as to-morn;\n",
      "And instant that or wanting, wounds to make them stried;\n",
      "And false heth, or soul speak a them write\n",
      "More belought the dream'd is no perjury,\n",
      "While it it is my flood me loudy and now;\n",
      "Hear not theirs, my gracious good injust of setprent,\n",
      "Stand, as in hot, excembrance to vawn was rest they so\n",
      "be the wear. one this timed tabbereford, and, they straw Earl leve\n",
      "This world as it be unquaments, death,\n",
      "To do I from here, thee their he nurpriless.\n",
      "\n",
      "TYBALK:\n",
      "I would rather shun;\n",
      "Her wilves as 'twered withouts!\n",
      "\n",
      "DUCHHESS OF YORK:\n",
      "Toich of Sir, he lord at God madaments;\n",
      "And shaments and speak thy what I news fand's deed\n",
      "By thee will purchars suddown to me, send my daught\n",
      "Let not unsulp youtell up, grace mys chamber:\n",
      "What innot the orld dare words:\n",
      "Master is, and with she blood, go bellow me brave.\n",
      "\n",
      "SICINIUS:\n",
      "Yet hears as brother'd kephame and for me swar\n",
      "A hook, so I besold.\n",
      "\n",
      "SICINIUS:\n",
      "Think, that he's to my death:\n",
      "It you foes, he is constant at ensire\n",
      "Than yours, sir, he is we well man, yours.\n",
      "Thie, I would bears as mine, though and for\n",
      "A greman: at worst what che store be his pair,\n",
      "Without accepts mun\n",
      "hoperateful pleison in tie? then hast thou mind,--\n",
      "Those perfy of two jove: I'll am'd him convey\n",
      "For the house--to\n",
      "Must sap-hearted and beathe authonourity's noble,\n",
      "It would shoop-blood make, body; but foot,\n",
      "Why looksip away pureses\n",
      "The now, to take in twenter on a stullen day.\n",
      "\n",
      "GLOUCESTER:\n",
      "So gone humble; 'tis none a move pared,\n",
      "To scape are to station much I tell ye\n",
      "Wicking have bone one.\n",
      "Tell, look be fairon! Why, might think'st droppose.\n",
      "\n",
      "Your fire, lords:\n",
      "What, the remory: feece your day, be poor cestor?\n",
      "\n",
      "YORK:\n",
      "a man heaven word it night work.\n",
      "\n",
      "KING HENRY VI\n",
      "\n",
      "GRERCY:\n",
      "We trattempet your honour, to England's brothers?\n",
      "\n",
      "DERBY:\n",
      "A great day's the facer: and there, not bring neat.\n",
      "\n",
      "WARWICK:\n",
      "To those could to selves ruitorator,\n",
      "Scond enside: we should hither these armster for me;\n",
      "The hold be Elian Henry. My Lord God be sour join\n",
      "Whereous crown: come fallow come.\n",
      "And speak I, do I woth I am a good two.\n",
      "I'll we call do not you are emparion.'\n",
      "Then royal a goes, to my soul, if\n",
      "I despissooner my lord, all than how me please.\n",
      "How for one he desires;\n",
      "Whose she we bill hearing Capollo\n",
      "And like slewing with the prosperonamied,\n",
      "So lispish trouble have dession, causinks,\n",
      "Sirs, not steepher:non haring a glad made tany cheel\n",
      "Due of Norfolk'd against right.\n",
      "\n",
      "ARTCHMOND:\n",
      "So muly, lesselves ere a sawaking and in to boy.\n",
      "\n",
      "ROMEO:\n",
      "Who cheeral, he shall he scraves of the presh,\n",
      "A should boollam,--Now coud loving to ourselves\n",
      "Than we prejued of govering will doth recortept;\n",
      "Nor mounter king with a long thou fainting.\n",
      "Who, woeds, so his something prevangely\n",
      "Let the abboll'd is face to be in the\n",
      "Tickent corance facious giving, sir, and viry,\n",
      "Fall, fail gent charict hawnone own burn\n",
      "And he misforten many herefort.\n",
      "\n",
      "Lord Marshal, while on all make tell of you;\n",
      "For have I should been conch for Earl die.\n",
      "How is the botten king, to did you bend yourship,\n",
      "become, yet beside of you dot me comerts\n",
      "And given fell the against me.\n",
      "\n",
      "PAULINA:\n",
      "Speak, we hath old ruth up ut's ercude.\n",
      "\n",
      "Post:\n",
      "So your wifer's speaks, call yes, but these lord;\n",
      "Old hath.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Vercy, my lord--\n",
      "\n",
      "WARDIV:\n",
      "Where is bodness thee duke his;\n",
      "Which all Cand not stand I have towardy, and hath gold,\n",
      "The crown me some at fight caliam,\n",
      "And for my bood more as at God,\n",
      "Whithen here of some affairitive the house\n",
      "And madam: They hourses I forge head it is;\n",
      "The king again; thus I come never them infewells\n",
      "To thy reason and look prese at Romes,\n",
      "Guistier than there arms, being to they see,\n",
      "Eithedo in mine earth it kiss thee forth may\n",
      "To an rown hus figns persons, furymer's\n",
      "head we befenced to the sains\n",
      "To this blood to be rest--whicker'd prove down'd,\n",
      "Whils miserimpt have such deliever thy land:\n",
      "'Teithing that she, in perful deservisity,\n",
      "Wall no deed in signal all of my fashkmits\n",
      "We reason. Were lurk in Fortunes time repetent;\n",
      "We are sains a spiriviol,\n",
      "Threst thou, which she things forward him,\n",
      "His mark agent loss-to you more, from templent,\n",
      "And my own thy both to my sweet still, lie,\n",
      "Stant thou have, but spul breathly liege.\n",
      "The great that Kets Franch of Richarms, may\n",
      "Thus that thou art as you, my Aufidius,\n",
      "What we may now whipe well, wearding to be me\n",
      "All be here shall deter, and alush you.\n",
      "\n",
      "First ServisliSman:\n",
      "Patre you that been and regnant to judge for it; and\n",
      "As we an rage's came the base ourity.\n",
      "\n",
      "HENRY"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mgenerate_continuous(\u001b[39m\"\u001b[39;49m\u001b[39mthe sacred flames will\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/nano-gpt/nn/transformer.py:82\u001b[0m, in \u001b[0;36mTransformer.generate_continuous\u001b[0;34m(self, start_sequence)\u001b[0m\n\u001b[1;32m     79\u001b[0m x \u001b[39m=\u001b[39m x[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_size:]\n\u001b[1;32m     81\u001b[0m \u001b[39m# Get the logits\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x)\n\u001b[1;32m     84\u001b[0m \u001b[39m# We are only interested in the last character\u001b[39;00m\n\u001b[1;32m     85\u001b[0m logits \u001b[39m=\u001b[39m logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nano-gpt/nn/model.py:25\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, batch, return_loss)\u001b[0m\n\u001b[1;32m     21\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput must be a batch of sequences. Shape should be (batch_size, sequence_length) but received \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_logits(x)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_loss:\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/projects/nano-gpt/nn/transformer.py:35\u001b[0m, in \u001b[0;36mTransformer.get_logits\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed(x)\n\u001b[1;32m     33\u001b[0m x \u001b[39m=\u001b[39m embed \u001b[39m+\u001b[39m pos_embed  \u001b[39m# Add them together, (B, T, E)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)  \u001b[39m# Apply the head\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# Apply the final transformation to obtain the logits\u001b[39;00m\n\u001b[1;32m     38\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nano-gpt/nn/transformer.py:176\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    175\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_pre_heads(x))\n\u001b[0;32m--> 176\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mff(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_pre_ff(x))\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nano-gpt/nn/transformer.py:161\u001b[0m, in \u001b[0;36mFF.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mff(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1495\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1495\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1496\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m             \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m             \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.generate_continuous(\"the sacred flames will\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9762ba4bc8c9531022aa6a27d6b5e4d0fcf29c38853484c685d55a003706ac42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
